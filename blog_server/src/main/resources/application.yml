server:
  port: 8080
　context-path: blog_server
#spring.jmx.default-domain: test
spring.jmx.enabled: false
spring:
     datasource:
         name: test
         url: jdbc:mysql://118.25.50.160:3306/sharism?useUnicode=true&characterEncoding=UTF-8&allowMultiQueries=true
         username: root
         password: Dys123456.
         # 使用druid数据源
         type: com.alibaba.druid.pool.DruidDataSource
         driver-class-name: com.mysql.jdbc.Driver
         filters: stat
         maxActive: 15
         initialSize: 1
         maxWait: 60000
         minIdle: 1
         timeBetweenEvictionRunsMillis: 60000
         minEvictableIdleTimeMillis: 300000
         validationQuery: select 'x'
         testWhileIdle: true
         testOnBorrow: false
         testOnReturn: false
         poolPreparedStatements: true
         maxOpenPreparedStatements: 20
     kafka:
        bootstrap-servers: 118.25.46.139:9092,118.25.47.192:9092,118.25.48.91:9092
        # 指定kafka 代理地址，可以多个
        producer:
           bootstrap-servers: 118.25.46.139:9092,118.25.47.192:9092,118.25.48.91:9092
           retries: 0
           # 每次批量发送消息的数量
           batch-size: 16384
           buffer-memory: 33554432
           # 指定消息key和消息体的编解码方式
           key-serializer: org.apache.kafka.common.serialization.StringSerializer
           value-serializer: org.apache.kafka.common.serialization.StringSerializer
           #bootstrap-servers: localhost:9092
        consumer:
           # 指定默认消费者group id
           group-id: foo
           # earliest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费。
           # latest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据。
           # none 当该topic下所有分区中存在未提交的offset时，抛出异常。
           auto-offset-reset: earliest
           #指定消息被消费之后自动提交偏移量（即消息的编号，表示消费到了哪个位置，消费者每消费完一条消息就会向kafka服务器汇报自己消消费到的那个消息的编号，以便于下次继续消费）。
           enable-auto-commit: true
           auto-commit-interval: 100
           # 指定消息key和消息体的编解码方式
           key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
           value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

mybatis:
  mapper-locations: classpath:mapping/*.xml
  type-aliases-package: com.sharism.blog_server.model



